**** Kubernetes Storage - demo: commands **** 
kubectl apply -f hostpath-volume-mount.yml   ## if you want to reuse the data or you want to work with the statefull app, these are the approach
cd /var/tmp/
ls
cd ..
cat /var/tmp/output.txt
kubectl delete -f hostpath-volume-mount.yml

### without hostpath 

kubectl apply -f emptyDir-volume.yml
kubectl get pods -o wide
kubectl describe pod redis-emptydir
kubectl exec -it redis-emptydir -- /bin/bash
root@redis-emptydir:/data# cd /data/redis
root@redis-emptydir:/data/redis# echo "Hello team, this file is created for testing >> testfile.txt"
Hello team, this file is created for testing >> testfile.txt
ls
root@redis-emptydir:/data/redis# pwd
/data/redis
kubectl delete -f emptyDir-volume.yml
kubectl apply -f emptyDir-volume.yml
kubectl exec -it redis-emptydir -- /bin/bash
root@redis-emptydir:/data# cd redis
touch testfile2.txt
ps -aux
bash: ps: command not found   ### first install
apt-get update
apt-get install procps
root@redis-emptydir:/data/redis# ps -aux
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND   ## output
redis          1  0.1  0.1  55580 14836 ?        Ssl  07:42   0:00 redis-server *:6379
root          21  0.0  0.0   4184  3328 pts/0    Ss   07:44   0:00 /bin/bash
root         216  100  0.0   8056  3996 pts/0    R+   07:50   0:00 ps -aux
root@redis-emptydir:/data/redis# kill 1
kubectl get pod redis-emptydir --watch  ## in a separate terminal
### note: so it doesnt matter container is restarted or deleted but as long as the pod will persist the data which was defined with emptydir also will persist!! ###

**** shared volume - demo **** 

kubectl apply -f common-volume.yml
kubectl get pod -o wide
kubectl describe pod shared-multi-container
kubectl exec -it shared-multi-container -- bash
Defaulted container "nginx-container" out of: nginx-container, debian-container  ## output
cd /usr/share/nginx/html
root@shared-multi-container:/usr/share/nginx/html# ls
index.html  ## output
echo "Custom Statement" >> index.html  ## let's append
cat index.html   ## nginx using the same file which has been writing by the debian container. Because they are sharing the shared volume
exit
**** persistent volume - demo ****

kubectl apply -f localhost-sc.yml   ## first create storage class
kubectl describe storageclass.storage.k8s.io/local-storage
kubectl apply -f my-persistent-volume.yml
kubectl describe persistentvolume/my-persistent-vol
kubectl get pv -o wide   ## output below:
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE    VOLUMEMODE
my-persistent-vol   1Gi        RWO            Recycle          Available           local-storage            100s   Filesystem
kubectl apply -f my-pvc.yml   ## it will use the existing persistent volume
kubectl describe persistentvolumeclaim/my-pvc    
kubectl get pv -o wide   ## output below
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE     VOLUMEMODE
my-persistent-vol   1Gi        RWO            Recycle          Available           local-storage            8m22s   Filesystem
kubectl get pvc -o wide   ## output below ## status is pending because, it is waiting for first consumer to be created before binding
NAME     STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    AGE     VOLUMEMODE
my-pvc   Pending                                      local-storage   2m29s   Filesystem
kubectl apply -f my-pv-pod.yml  ## let's create the resource
kubectl get pv -o wide   ## as soon as we've created a resource on our PVC, STATUS and CLAIM changed
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS    REASON   AGE   VOLUMEMODE
my-persistent-vol   1Gi        RWO            Recycle          Bound    default/my-pvc   local-storage            16m   Filesystem
kubectl get pvc -o wide   ## output below:STATUS, VOLUME, CAPACITY and ACCESS MODES changed 
NAME     STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS    AGE   VOLUMEMODE
my-pvc   Bound    my-persistent-vol   1Gi        RWO            local-storage   13m   Filesystem
kubectl edit pvc my-pvc    ## edited storage from 100 to 200
persistentvolumeclaim/my-pvc edited
kubectl delete -f my-pv-pod.yml   ## first delete the pod
kubectl delete -f my-pvc.yml
kubectl get pv -o wide   ## STATUS again is available beacuse rec policy is recycle
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE   VOLUMEMODE
my-persistent-vol   1Gi        RWO            Recycle          Available           local-storage            31m   Filesystem
